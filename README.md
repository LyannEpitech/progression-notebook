# ğŸ“Š Epitech Pool â€“ Progression Analyzer

A tool to analyze Pool results and visualize student and promotion statistics, available as a **Jupyter Notebook** or an **interactive Streamlit dashboard**.

---

## ğŸ“š Dependencies

This project uses the following libraries:

- **matplotlib** â€“ Static graph generation (notebook)
- **Jupyter Notebook** â€“ Notebook execution
- **NumPy** â€“ Mathematical operations
- **Pandas** â€“ Dataset processing
- **Streamlit** â€“ Interactive web dashboard
- **Plotly** â€“ Interactive charts (dashboard)

All dependencies are listed in `requirements.txt`.

---

## âš™ï¸ Installation

1. **Clone the repository**

```bash
git clone <repository_url>
cd <repository_name>
```

2. **Create a virtual environment**

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

---

## ğŸ” Environment Variables

The project uses a `.env` file for API authentication (Hermes API credentials).

1. **Create a `.env` file from the example**

```bash
cp .env.example .env
```

Then edit `.env` with your actual credentials:

```bash
PAT=your_pat_here
PAT_ID=your_pat_id_here
HERMES_ENDPOINT=https://api.epitest.eu/api/
```

### Available Variables

| Variable | Description | Required | Default |
|----------|-------------|----------|---------|
| `PAT` | Personal Access Token | **Yes** | - |
| `PAT_ID` | PAT identifier | **Yes** | - |
| `HERMES_ENDPOINT` | Hermes API endpoint | No | `https://api.epitest.eu/api/` |

**Notes:**
- `PAT` and `PAT_ID` are obtained from your Epitech account (Profile â†’ API Tokens)
- These tokens are used for all API calls to fetch student results
- âš ï¸ **Never commit the `.env` file** to version control. It's already in `.gitignore`

---

## â–¶ï¸ Getting started

1. Create a `datasets` folder at the root of the repository.
2. Add your Pool CSV datasets inside this folder (ou upload directement depuis le dashboard).

You can download tested datasets from:
ğŸ‘‰ https://hermes.epitest.eu/
Go to the results page and click on **"CSV (All instances)"**.

âš ï¸ You need at least **two Pool days datasets** for the graphs to work properly.

---

## ğŸ““ Running the Notebook

```bash
jupyter notebook
```

1. Open `progression.ipynb`.
2. Click **Run All**.
3. When prompted, copy/paste the notebook link displayed in the terminal if required.

Graphs are generated and saved automatically in `plots_students/`.

---

## ğŸŒ Running the Dashboard

### Data Sources

The dashboard supports 3 data sources (selectable in the sidebar):

| Source | Description | Requirements |
|--------|-------------|--------------|
| **CSV** | Load from local CSV files in `datasets/` folder | CSV files in `datasets/` |
| **API** | Fetch live data from Hermes API | `.env` file with credentials |
| **Sync** | Synchronize CSV files from API | `.env` file with credentials |

### Local (without Docker)

```bash
# Standard mode
streamlit run dashboard.py

# With custom port
streamlit run dashboard.py --server.port 8502
```

### With Docker

```bash
# Build and run (with environment variables)
docker-compose up --build

# Or detached mode
docker-compose up -d --build
```

**Docker with environment variables:**

If your `.env` file is not automatically loaded, pass variables explicitly:

```bash
# Option 1: Export before docker-compose
export HERMES_EMAIL=your.email@epitech.eu
export HERMES_PASSWORD=your_password
docker-compose up -d --build

# Option 2: Create a docker-compose.override.yml (not committed)
```

The dashboard is accessible at `http://localhost:8501`

**Notes Docker :**
- Les datasets sont persistÃ©s via un volume (`./datasets`)
- Les graphs gÃ©nÃ©rÃ©s sont sauvegardÃ©s dans `./plots_students`

---

Le dashboard comprend les sections suivantes :

| Section | Description |
|---|---|
| **KPIs** | Active students, global average, best student, hardest day |
| **Class progression** | Interactive line chart of daily class averages |
| **Individual view** | Per-student curve vs. class average + score table |
| **Hardest days** | Bar chart of the N days with the lowest scores (configurable) |
| **Leaderboard** | Students ranked by average score with color gradient |

The sidebar lets you filter students and adjust the number of hardest days shown.

---

## ğŸš€ Features

- âœ… Generate cleaned daily results in the format `[login, percentage]`
- ğŸ“ **Upload direct de datasets** depuis le dashboard (drag & drop) â€“ mÃªme quand vide
- ğŸ—‘ï¸ **Clear data** â€“ bouton pour supprimer tous les datasets en un clic
- ğŸ“ˆ Class average progression chart (static + interactive)
- ğŸ‘¨â€ğŸ“ Individual student progression charts â†’ saved in `plots_students/`
- ğŸ“Š Bar chart highlighting the hardest Pool days
- ğŸŒ Interactive Streamlit dashboard with Plotly charts and filters
- ğŸ³ **Docker support** â€“ dÃ©ploiement facile avec `docker-compose`
- ğŸ”Œ **Hermes API integration** â€“ Fetch live data directly from Epitech's API
- ğŸ•µï¸ **Suspicious submissions detection** â€“ 4 algorithms to detect cheating patterns:
  - **Copieurs** â€“ Students with similar scores across multiple days
  - **Pics isolÃ©s** â€“ Isolated high scores (>70%) surrounded by low scores (<30%)
  - **Montagnes russes** â€“ Rapid alternations indicating selective cheating
  - **Copies collectives** â€“ Clusters of students with identical scores
- ğŸ§ª **Unit tests** â€“ Comprehensive test suite with pytest (16 tests)
- ğŸ”„ **CI/CD** â€“ GitHub Actions workflow for automated testing

---

## ğŸ—ºï¸ Roadmap

### âœ… Completed
- ğŸ”„ Automatic dataset retrieval from Hermes
- ğŸ•µï¸ Suspicious behavior detection algorithms
- ğŸ§ª Unit tests with pytest
- ğŸ”„ CI/CD with GitHub Actions

### ğŸš§ In Progress / Planned
- ğŸ“Š Export suspicious reports (PDF/Excel)
- ğŸ”Œ REST API (Nest.js backend serving stats + graphs)
- ğŸ“± Email alerts for new suspicious patterns
- ğŸ“ˆ Historical tracking (week-over-week comparison)
- ğŸ” Single Sign-On (SSO) Epitech integration

---

## ğŸ§ª Running Tests

The project includes a comprehensive test suite with **16 tests** covering detection algorithms and API functions.

### Install test dependencies

```bash
pip install -r requirements-dev.txt
```

### Run all tests

```bash
pytest
```

### Run with coverage

```bash
pytest --cov=.
```

### Run specific test file

```bash
pytest tests/test_detection.py
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ .github/workflows/      # CI/CD configuration
â”‚   â””â”€â”€ tests.yml           # GitHub Actions workflow
â”œâ”€â”€ datasets/               # CSV files (mounted volume in Docker)
â”œâ”€â”€ datasets_backup/        # Backup folder for development
â”œâ”€â”€ plots_students/         # Generated plots
â”œâ”€â”€ tests/                  # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pytest.ini          # pytest configuration
â”‚   â”œâ”€â”€ test_api.py         # API tests
â”‚   â”œâ”€â”€ test_detection.py   # Detection algorithm tests
â”‚   â””â”€â”€ README.md           # Test documentation
â”œâ”€â”€ .env                    # Environment variables (not committed)
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ dashboard.py            # Streamlit dashboard
â”œâ”€â”€ hermes_api.py           # Hermes API integration
â”œâ”€â”€ progression.ipynb       # Jupyter notebook
â”œâ”€â”€ requirements.txt        # Full dependencies (notebook + dashboard)
â”œâ”€â”€ requirements-dashboard.txt  # Light dependencies (dashboard only)
â”œâ”€â”€ requirements-dev.txt    # Development dependencies (tests)
â”œâ”€â”€ Dockerfile              # Docker image
â”œâ”€â”€ docker-compose.yml      # Docker orchestration
â””â”€â”€ README.md
```
